{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Layers in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The layer is created by using the following format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Conv2D(filters, kernel_size, strides, padding, activation='relu', input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arguments\n",
    "Required arguments:\n",
    "\n",
    "- filters - no. filters.\n",
    "- kernel_size - number specifying both the height and width of the square convolution window.\n",
    "- input_shape - tuple specifying the height, width, and depth (in that order) of the input.\n",
    "\n",
    "Optional parameters:\n",
    "\n",
    "- strides - the stride of the convolution. It's 1 by default.\n",
    "- padding - 'same' indicates padding.\n",
    "- activation - strongly encouraged to add a ReLU activation function to every convolutional layer in CNNs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "- An input layer accepts grayscale images that \n",
    "  are 200 by 200 pixels (corresponding to a 3D \n",
    "  array with height 200, width 200, and depth 1).\n",
    "  \n",
    "- Next layer is a convolutional layer with 16 filters, \n",
    "  each with a width and height of 2. The filter jumps \n",
    "  two pixels at a time when performing a convolution. \n",
    "  \n",
    "- Padding is set to 'valid' by default, meaning the image \n",
    "  is not padded with zeros. \n",
    "'''\n",
    "\n",
    "Conv2D(filters=16,\n",
    "       kernel_size=2,\n",
    "       strides=2, \n",
    "       activation='relu', \n",
    "       input_shape=(200, 200, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "- Second layer in the CNN is set as a convolutional\n",
    "  layer that takes the layer from Example 1 as input.\n",
    "  \n",
    "- This layer has 32 filters, each with a height and width\n",
    "  of 3.\n",
    "  \n",
    "- Filter stride/jump 1 pixel at a time during a convolution.\n",
    "\n",
    "- To see all regions of the previous layer, the padding is set \n",
    "  to 'same' to enable padding of with zeros.\n",
    "'''\n",
    "\n",
    "Conv2D(filters=32, kernel_size=3, padding='same', activation='relu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 100, 100, 16)      80        \n",
      "=================================================================\n",
      "Total params: 80\n",
      "Trainable params: 80\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=16, \n",
    "                 kernel_size=2, \n",
    "                 strides=2,\n",
    "                 padding='valid', \n",
    "                 activation='relu', \n",
    "                 input_shape=(200, 200, 1)))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formula: Number of Parameters in a Convolutional Layer\n",
    "The number of parameters in a convolutional layer depends on the suplied values of *filters, kernel_size*, and *input_shape*.\n",
    "\n",
    "- **K** - the number of filters in the convolutional layer\n",
    "- **F** - the height and width of the convolutional filters\n",
    "- **D_in** - the depth of the previous layer\n",
    "\n",
    "Notice that **K** = *filters*, and **F** = *kernel_size*. Likewise, **D_in** is the last value in the *input_shape* tuple.\n",
    "\n",
    "Since there are **F x F x D_in** weights per filter, and the convolutional layer is composed of K filters, the total number of weights in the convolutional layer is **K x F x F x D_in**. \n",
    "\n",
    "Since there is one bias term per filter, the convolutional layer has K biases. Thus, the number of parameters in the convolutional layer is given by **K x F x F x D_in + K**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formula: Shape of a Convolutional Layer\n",
    "The shape of a convolutional layer depends on the supplied values of *kernel_size, input_shape, padding*, and *stride*.\n",
    "\n",
    "- **K** - the number of filters in the convolutional layer\n",
    "- **F** - the height and width of the convolutional filters\n",
    "- **S** - the stride of the convolution\n",
    "- **H_in** - the height of the previous layer\n",
    "- **W_in** - the width of the previous layer\n",
    "\n",
    "The **depth** of the convolutional layer will always equal the number of filters **K**. \n",
    "\n",
    "If **padding = 'same'**, then the spatial dimensions of the convolutional layer are the following:\n",
    "\n",
    "- **height** = ceil(float(H_in) / float(S))\n",
    "- **width** = ceil(float(W_in) / float(S))\n",
    "\n",
    "If **padding = 'valid'**, then the spatial dimensions of the convolutional layer are the following:\n",
    "\n",
    "- **height** = ceil(float(H_in - F + 1) / float(S))\n",
    "- **width** = ceil(float(W_in - F + 1) / float(S))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 64, 64, 32)        896       \n",
      "=================================================================\n",
      "Total params: 896\n",
      "Trainable params: 896\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "No. parameters: 896\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, \n",
    "                 kernel_size=3, \n",
    "                 strides=2,\n",
    "                 padding='same', \n",
    "                 activation='relu', \n",
    "                 input_shape=(128, 128, 3)))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "K, F, D_in = 32, 3, 3 #no.filters, kernel_size, input_depth\n",
    "print(\"\\nNo. parameters: %d\" % (K * F * F * D_in + K)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth of the convolutional layer: 32\n",
      "Width of the convolutional layer: 64\n"
     ]
    }
   ],
   "source": [
    "from math import ceil\n",
    "\n",
    "print(\"Depth of the convolutional layer: %d\" % K) # always equal to no. filters in the previous layer\n",
    "\n",
    "# width = ceil(float(W_in) / float(S))\n",
    "print(\"Width of the convolutional layer: %d\" % ceil(float(128) / 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
