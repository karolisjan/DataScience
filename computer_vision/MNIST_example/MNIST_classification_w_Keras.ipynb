{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of MNIST database with a MLP\n",
    "More info on the database can be found [here](http://yann.lecun.com/exdb/mnist/).\n",
    "\n",
    "## Load the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise the first six training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIEAAADOCAYAAACpdxJrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1549a8264e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "fig, ax = plt.subplots(ncols=6, figsize=(20, 20))\n",
    "for i in range(6):\n",
    "    ax[i].imshow(X_train[i], cmap='gray')\n",
    "    ax[i].set_title(str(y_train[i]))\n",
    "    ax[i].axis(\"off\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rescale the images\n",
    "\n",
    "Every pixel in the images have integer values in range [0, 255] (where 0 - black, 255 - white). The pixels need to be rescale from [0, 255] to [0, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess labels\n",
    "Apply One-Hot encoding to the labels, i.e. 7 -> 0 0 0 0 0 0 0 1 0 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integer-valued labels:\n",
      "[5 0 4 1 9 2 1 3 1 4]\n",
      "\n",
      "One-Hot encoded labels:\n",
      "[[ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "print('Integer-valued labels:')\n",
    "print(y_train[:10])\n",
    "\n",
    "# Apply One-Hot encoding\n",
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)\n",
    "\n",
    "print('\\nOne-Hot encoded labels:')\n",
    "print(y_train[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP for Image Classifacation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_3 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer of 784 nodes\n",
    "# Flatten layer takes in a matrix and turns it into a vector\n",
    "model.add(Flatten(input_shape=X_train.shape[1:]))\n",
    "\n",
    "# 1st hidden layer of 512 nodes\n",
    "model.add(Dense(512, activation='relu'))\n",
    "\n",
    "# Add dropout to the 1st hidden layer. 0.2 is the prob. of Dropout\n",
    "model.add(Dropout(0.2)) \n",
    "\n",
    "# 2nd hidden layer of 512 nodes\n",
    "model.add(Dense(512, activation='relu'))\n",
    "\n",
    "# Add dropout to the 2nd hidden layer\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Output layer - 10 labels\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the model\n",
    "List of available optimisers in Keras:\n",
    " - [SGD](http://sebastianruder.com/optimizing-gradient-descent/index.html#stochasticgradientdescent)\n",
    " - [RMSprop](http://sebastianruder.com/optimizing-gradient-descent/index.html#rmsprop)\n",
    " - [Adagrad](http://sebastianruder.com/optimizing-gradient-descent/index.html#adagrad)\n",
    " - [Adadelta](http://sebastianruder.com/optimizing-gradient-descent/index.html#adadelta)\n",
    " - [AdaMax](http://sebastianruder.com/optimizing-gradient-descent/index.html#adamax)\n",
    " - [Nadam](http://sebastianruder.com/optimizing-gradient-descent/index.html#nadam)\n",
    " - TFOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Validation\n",
    "\n",
    "- [ModelCheckpoint](https://keras.io/callbacks/#modelcheckpoint)\n",
    "- [EarlyStopping](https://keras.io/callbacks/#earlystopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "46720/48000 [============================>.] - ETA: 0s - loss: 0.0131 - acc: 0.9973Epoch 00000: val_loss improved from inf to 0.08041, saving model to mnist.model.best.hdf5\n",
      "48000/48000 [==============================] - 1s - loss: 0.0129 - acc: 0.9973 - val_loss: 0.0804 - val_acc: 0.9896\n",
      "Epoch 2/10\n",
      "47104/48000 [============================>.] - ETA: 0s - loss: 0.0117 - acc: 0.9974Epoch 00001: val_loss did not improve\n",
      "48000/48000 [==============================] - 1s - loss: 0.0115 - acc: 0.9974 - val_loss: 0.0956 - val_acc: 0.9888\n",
      "Epoch 3/10\n",
      "46720/48000 [============================>.] - ETA: 0s - loss: 0.0108 - acc: 0.9978Epoch 00002: val_loss did not improve\n",
      "48000/48000 [==============================] - 1s - loss: 0.0107 - acc: 0.9978 - val_loss: 0.0986 - val_acc: 0.9888\n",
      "Epoch 4/10\n",
      "46720/48000 [============================>.] - ETA: 0s - loss: 0.0098 - acc: 0.9979Epoch 00003: val_loss did not improve\n",
      "48000/48000 [==============================] - 1s - loss: 0.0097 - acc: 0.9979 - val_loss: 0.0942 - val_acc: 0.9883\n",
      "Epoch 5/10\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.0102 - acc: 0.9981Epoch 00004: val_loss did not improve\n",
      "48000/48000 [==============================] - 1s - loss: 0.0105 - acc: 0.9981 - val_loss: 0.0938 - val_acc: 0.9887\n",
      "Epoch 6/10\n",
      "46464/48000 [============================>.] - ETA: 0s - loss: 0.0098 - acc: 0.9980Epoch 00005: val_loss improved from 0.08041 to 0.07886, saving model to mnist.model.best.hdf5\n",
      "48000/48000 [==============================] - 1s - loss: 0.0095 - acc: 0.9981 - val_loss: 0.0789 - val_acc: 0.9901\n",
      "Epoch 7/10\n",
      "46976/48000 [============================>.] - ETA: 0s - loss: 0.0108 - acc: 0.9980Epoch 00006: val_loss did not improve\n",
      "48000/48000 [==============================] - 1s - loss: 0.0106 - acc: 0.9980 - val_loss: 0.0965 - val_acc: 0.9885\n",
      "Epoch 8/10\n",
      "47616/48000 [============================>.] - ETA: 0s - loss: 0.0111 - acc: 0.9979Epoch 00007: val_loss did not improve\n",
      "48000/48000 [==============================] - 1s - loss: 0.0110 - acc: 0.9979 - val_loss: 0.1015 - val_acc: 0.9874\n",
      "Epoch 9/10\n",
      "46976/48000 [============================>.] - ETA: 0s - loss: 0.0121 - acc: 0.9978Epoch 00008: val_loss did not improve\n",
      "48000/48000 [==============================] - 1s - loss: 0.0121 - acc: 0.9978 - val_loss: 0.0968 - val_acc: 0.9884\n",
      "Epoch 10/10\n",
      "47232/48000 [============================>.] - ETA: 0s - loss: 0.0076 - acc: 0.9983Epoch 00009: val_loss did not improve\n",
      "48000/48000 [==============================] - 1s - loss: 0.0075 - acc: 0.9984 - val_loss: 0.0890 - val_acc: 0.9892\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='mnist.model.best.hdf5',\n",
    "                               verbose=1,\n",
    "                               save_best_only=True)\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', \n",
    "                           min_delta=1e-4,\n",
    "                           patience=5, \n",
    "                           verbose=1, \n",
    "                           mode='auto')\n",
    "\n",
    "history = model.fit(X_train, \n",
    "                    y_train, \n",
    "                    batch_size=128,\n",
    "                    epochs=10,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[checkpointer, early_stop],\n",
    "                    verbose=1, \n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the classification accuracy on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 98.3900%\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "accuracy = 100 * score[1]\n",
    "\n",
    "print(\"Test accuracy: %.4f%%\" % accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
