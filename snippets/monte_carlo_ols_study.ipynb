{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo simulation study using R\n",
    "\n",
    "## Goal of the study 1\n",
    "\n",
    "**Prove that  OLS estimators of Generalised Linear Regression (GLR) model are Best Linear Unbiased Estimators (BLUEs)**\n",
    "\n",
    "<br>\n",
    "\n",
    "Generalised Linear Regression mode is given as:\n",
    "\n",
    "$$\n",
    "    Y = X\\beta + u\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "* $Y$ is $n\\times1$ dependent vector\n",
    "    \n",
    "* $X$ is $n\\times k$ independent variables matrix\n",
    "    \n",
    "* $\\beta$ is $k\\times1$ unknown parameters vector\n",
    "    \n",
    "* $u$ is $n\\times1$ error term vector\n",
    "\n",
    "<br>\n",
    "Assumptions:\n",
    "\n",
    "1. $E(u) = 0$ and $E(uu^{\\prime}) = \\sigma_{u}^{2} I_{u}$ where $\\sigma = \\sqrt{\\frac{\\sum_{i = 1}^{n} (x_{i} - \\bar{x})^{2}}{n - 1}}$ is standard deviation.\n",
    "\n",
    "2. $X$ is non-stochastic matrix and $cov(X, u) = 0$\n",
    "\n",
    "3. $X$ is full column rank matrix, i.e. $rank(X) = k$\n",
    "\n",
    "<br>\n",
    "The OLS estimator is given as:\n",
    "\n",
    "$$\n",
    "    \\hat{\\beta}_{OLS} = (X^{\\prime}X)^{-1}X^{\\prime}Y\n",
    "$$\n",
    "\n",
    "<br>\n",
    "The bias and variance of OLS estimators are given as:\n",
    "\n",
    "$$bias(\\hat{\\beta}_{OLS}) = \\hat{\\beta}_{OLS} - \\beta$$\n",
    "\n",
    "$$var(\\hat{\\beta}_{OLS}) = \\sigma_{u}^{2}(X^{\\prime}X)^{-1}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cufflinks as cf\n",
    "import plotly.offline as opy\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "import rpy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         bias    variance\n",
       "1 1.00325e-05 0.009989517\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "\n",
    "library(ggplot2)\n",
    "\n",
    "n_trials = 1000\n",
    "beta = c(1, 3) # true beta\n",
    "sample_size = 100\n",
    "X = cbind(1, runif(sample_size, -1, 1))\n",
    "bias_results = c()\n",
    "var_results = c()\n",
    "\n",
    "get_ols_estimator <- function(Y, X) {\n",
    "    solve(t(X) %*% X) %*% t(X) %*% Y\n",
    "}\n",
    "\n",
    "for (trial in 1:n_trials) {\n",
    "    u = rnorm(sample_size, 0, 1) # error term\n",
    "    y = X %*% beta + u\n",
    "    beta_ols = get_ols_estimator(y, X)\n",
    "    bias_results = c(bias_results, beta_ols - beta)\n",
    "    var_results = c(var_results, var(u) * solve(t(X) %*% X))\n",
    "}\n",
    "\n",
    "results = cbind(mean(bias_results), mean(var_results))\n",
    "results = as.data.frame(results)\n",
    "colnames(results) = c('bias', 'variance')\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal of study 2\n",
    "\n",
    "**Compare the performance of OLS and Generalised Least Squares (GLS) estimators in multiple linear regression model when the errors are correlated with first-order autoregressive, i.e. AR(1)**\n",
    "\n",
    "\n",
    "The second and third assumptions are still valid but the first assumption is replaced with the following:\n",
    "\n",
    "$$\n",
    "    u_t = \\rho u_{t-1} + \\epsilon_t \\quad \\forall \\quad \\epsilon_{t} ~ N(0, \\sigma_{\\epsilon}^{2})\n",
    "$$\n",
    "\n",
    "$$\n",
    "    E(\\epsilon_{t}, \\epsilon_{s}) = 0 \\quad \\forall \\quad t \\neq s\n",
    "$$\n",
    "\n",
    "$$\n",
    "    E(\\epsilon_{t}, u_{t-1}) = 0\n",
    "$$\n",
    "\n",
    "<br>\n",
    "The GLS estimator is given as:\n",
    "\n",
    "$$\n",
    "    \\hat{\\beta}_{GLS} = (X^{\\prime}\\Omega^{-1}X)^{-1}X^{\\prime}\\Omega^{-1}Y\n",
    "$$\n",
    "\n",
    "<br>\n",
    "where:\n",
    "\n",
    "$$\n",
    "    \\Omega = E(uu^{\\prime}) = \\frac{ \\sigma_{\\epsilon}^{2} }{ 1 - \\rho } \\begin{bmatrix}\n",
    "    1 & \\rho & \\rho^{2} & \\dots  & \\rho^{n-1} \\\\\n",
    "    \\rho & 1 & \\rho & \\dots  & \\rho^{n-2} \\\\\n",
    "    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    \\rho^{n-1} & \\rho^{n-2} & \\rho^{n-3} & \\dots  & 1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Since the elements of $\\Omega$ are usually unknown, $\\rho$ can be estimated using:\n",
    "\n",
    "$$\n",
    "    \\hat{\\rho} = \\frac{ \\sum_{i=2}^{n} \\hat{u}_{i}\\hat{u}_{i-1} }{ \\sum_{i=2}^{n} \\hat{u}_{i-1}^{2} }\n",
    "$$\n",
    "\n",
    "$$\n",
    "    \\hat{\\sigma}_{\\epsilon}^{2} = \\frac{ \\sum_{i=1}^{n} \\hat{\\epsilon}_{i}^{2} }{ n - K }\n",
    "$$\n",
    "\n",
    "<br>\n",
    "where:\n",
    "\n",
    "* $\\hat{\\epsilon}_{1} = \\hat{u}\\sqrt{1 - \\hat{\\rho}^{2}}$\n",
    "* $\\hat{\\epsilon}_{i} = \\hat{u}_{i} - \\hat{\\rho}\\hat{u}_{i - 1} \\quad \\forall \\quad i = 2, ..., N$\n",
    "\n",
    "<br>\n",
    "The bias and variance of OLS and GLS estimators in this model are given as:\n",
    "\n",
    "$$bias(\\hat{\\beta}_{OLS}) = \\hat{\\beta}_{OLS} - \\beta$$\n",
    "\n",
    "$$bias(\\hat{\\beta}_{GLS}) = \\hat{\\beta}_{GLS} - \\beta$$\n",
    "\n",
    "$$var(\\hat{\\beta}_{OLS}) = (X^{\\prime}X)^{-1}X^{\\prime}\\Omega X(X^{\\prime}X)^{-1}$$\n",
    "\n",
    "$$var(\\hat{\\beta}_{GLS}) = (X^{\\prime}\\Omega^{-1}X)^{-1}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            OLS bias      GLS bias OLS variance GLS variance\n",
       "beta_0 -0.0001166151  0.0010654905    0.1118213   0.11083473\n",
       "beta_1  0.0051626033 -0.0006069895    0.1112929   0.06206032\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "\n",
    "n_trials = 1000\n",
    "beta = c(1, 1)\n",
    "sample_size = 100\n",
    "rho = 0.5\n",
    "X = cbind(1, runif(sample_size, -1, 1))\n",
    "\n",
    "estimate_omega <- function(u) {\n",
    "    n = length(u)\n",
    "    \n",
    "    rho_hat = (t(u[-n]) %*% u[-1]) / sum(u[-1]^2)\n",
    "    dim(rho_hat) = NULL\n",
    "    \n",
    "    if (rho_hat > 1) {\n",
    "        rho_hat = 0.99\n",
    "    } else if (rho_hat < 0) {\n",
    "        rho_hat = 0.005\n",
    "        \n",
    "    }\n",
    "    \n",
    "    epsilon_hat = NA\n",
    "    epsilon_hat[1] = u[1] * sqrt((1 - rho_hat^2))\n",
    "    epsilon_hat[2:n] = u[-1] + rho_hat * u[-n]\n",
    "    sigma2_epsilon_hat = sum(epsilon_hat^2) / (n - 2)\n",
    "    dim(sigma2_epsilon_hat) = NULL\n",
    "\n",
    "    v = matrix(NA, nrow=n, ncol=n)\n",
    "    \n",
    "    for (i in 1:n) {\n",
    "        for (j in 1:n) {\n",
    "            v[i, j] = rho_hat^abs(i - j)\n",
    "        }\n",
    "    }   \n",
    "    \n",
    "     (sigma2_epsilon_hat / (1 - rho_hat^2)) * v\n",
    "}\n",
    "\n",
    "get_gls_estimator <- function(Y, X, omega) {\n",
    "    solve(t(X) %*% solve(omega) %*% X) %*% t(X) %*% solve(omega) %*% Y\n",
    "}\n",
    "\n",
    "total_result = matrix(0, nrow=2, ncol=4)\n",
    "\n",
    "for (trial in 1:n_trials) {\n",
    "    epsilon = rnorm(sample_size, 0, 1)\n",
    "    u = c(0)\n",
    "    u[1] = epsilon[1] / sqrt(1 - rho^2)\n",
    "    \n",
    "    for (i in 2:sample_size) {\n",
    "        u[i] = rho * u[i - 1] + epsilon[i]\n",
    "    }\n",
    "    \n",
    "    y = X %*% beta + u\n",
    "    \n",
    "    omega = estimate_omega(u)\n",
    "    beta_ols = get_ols_estimator(y, X)\n",
    "    beta_gls = get_gls_estimator(y, X, omega)\n",
    "    \n",
    "    bias_beta_hat_ols = beta_ols - beta\n",
    "    bias_beta_hat_gls = beta_gls - beta\n",
    "\n",
    "    var_beta_hat_ols = diag(solve(t(X) %*% X) %*% t(X) %*% omega %*% X %*% solve(t(X) %*% X))\n",
    "    var_beta_hat_gls = diag(solve(t(X) %*% solve(omega) %*% X))\n",
    "    \n",
    "    result = cbind(bias_beta_hat_ols, bias_beta_hat_gls, var_beta_hat_ols, var_beta_hat_gls)\n",
    "    rownames(result) = c('beta_0', 'beta_1')\n",
    "    colnames(result) = c('OLS bias', 'GLS bias', 'OLS variance', 'GLS variance')\n",
    "    \n",
    "    total_result = total_result + result\n",
    "}\n",
    "\n",
    "as.data.frame(total_result / n_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rpy2",
   "language": "python",
   "name": "rpy2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
