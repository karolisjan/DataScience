{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximum likelihood estimation (MLE)\n",
    "\n",
    "MLE is a method that determines values for the parameters of a model. The parameter values are found such that they maximise the likelihood that the processes described by the model produced the data that were actually observed.\n",
    "\n",
    "For example, the **probability density** of observing a single data point x, that is generated from a Gaussian distribution is given by:\n",
    "\n",
    "$$\n",
    "    P(x; \\mu, \\sigma) = \\frac{ 1 }{ \\sigma \\sqrt{2 \\pi} } \\exp{ -( \\frac{ (x - \\mu)^{2} }{ 2 \\sigma^{2} } ) }\n",
    "$$\n",
    "\n",
    "Total (joint) probability density of observing the three data points 9, 9.5, 11:\n",
    "\n",
    "$$\n",
    "    P(9, 9.5, 11; \\mu, \\sigma) = \\frac{ 1 }{ \\sigma \\sqrt{2 \\pi} } \\exp{ -( \\frac{ (9 - \\mu)^{2} }{ 2 \\sigma^{2} } ) } \\times \\frac{ 1 }{ \\sigma \\sqrt{2 \\pi} } \\exp{ -( \\frac{ (9.5 - \\mu)^{2} }{ 2 \\sigma^{2} } ) } \\times \\frac{ 1 }{ \\sigma \\sqrt{2 \\pi} } \\exp{ -( \\frac{ (11 - \\mu)^{2} }{ 2 \\sigma^{2} } ) }\n",
    "$$\n",
    "\n",
    "Log-likelihood of the above:\n",
    "\n",
    "$$\n",
    "    \\ln{ (P(9, 9.5, 11; \\mu, \\sigma)) } = \\ln{ (\\frac{ 1 }{ \\sigma \\sqrt{2 \\pi} }) } - \\frac{ (9 - \\mu)^{2} }{ 2 \\sigma^{2} } + \\ln{ (\\frac{ 1 }{ \\sigma \\sqrt{2 \\pi} }) } - \\frac{ (9.5 - \\mu)^{2} }{ 2 \\sigma^{2} } + \\ln{ (\\frac{ 1 }{ \\sigma \\sqrt{2 \\pi} }) } - \\frac{ (11 - \\mu)^{2} }{ 2 \\sigma^{2} } \n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "    \\ln{ (P(9, 9.5, 11; \\mu, \\sigma)) } = -3 \\ln{ (\\sigma) } - \\frac{ 3 }{ 2 }\\ln{ (2 \\pi) } - \\frac{ 1 }{ 2 \\sigma^{2} }[ (9 - \\mu)^{2} + (9.5 - \\mu)^{2} + (11 - \\mu)^{2} ]\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "    \\frac{ \\partial{\\ln{ (P(9, 9.5, 11; \\mu, \\sigma)}) } }{ \\partial{\\mu} } = \\frac{ 1 }{ \\sigma^{2} }[9 + 9.5 + 11 - 3 \\mu] = 0\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "    \\mu = \\frac{ 9 + 9.5 + 11 }{ 3 }\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "### The difference between likelihood and probability\n",
    "\n",
    "$$\n",
    "    L(\\mu, \\sigma; data) = P(data; \\mu, \\sigma)\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "The definition of $L(\\mu, \\sigma; data)$ is given as *the likelihood of the parameters $\\mu$ and $\\sigma$ taking certain values given the observed data*, where as $P(data; \\mu, \\sigma)$ is defined as *the probability density of observing the data given parameters $\\mu$ and $\\sigma$.*\n",
    "\n",
    "### Least Squares Estimate is the same as MLE under a Gaussian model\n",
    "\n",
    "Intuition: the predictions is equal to signal plus white noise (zero mean).\n",
    "\n",
    "$$\n",
    "    Y = f^{*}(X) + \\epsilon = X \\beta^{*} + \\epsilon \\quad \\forall \\quad \\epsilon \\text{ ~ } \\mathcal{N}(0, \\sigma^{2}I)\n",
    "$$\n",
    "\n",
    "$$\n",
    "    Y \\text{ ~ } \\mathcal{N}(0, \\sigma^{2}I)\n",
    "$$\n",
    "\n",
    "$$\n",
    "    \\hat{\\beta}_{MLE} = \\underset{\\beta}{\\arg\\max} \\ln{ (P( (y_{i}, x_{i})_{i=1}^{n} | \\beta, \\sigma^{2} )) } = \\underset{\\beta}{\\arg\\min} \\sum_{i=1}^{n} (y_{i} - x_{i}\\beta)^{2}\n",
    "$$\n",
    "\n",
    "### Regularised Least Squares and maximum a posteriori MAP estimate\n",
    "\n",
    "$$\n",
    "    \\hat{\\beta}_{MAP} = \\underset{\\beta}{\\arg\\max} \\ln{ (P( (y_{i}, x_{i})_{i=1}^{n} | \\beta, \\sigma^{2} )) } + \\ln{(P(\\beta)}) = \\underset{\\beta}{\\arg\\min} \\sum_{i=1}^{n} (y_{i} - x_{i}\\beta)^{2} + \\lambda ||\\beta||_{2}^{2}\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "* $\\beta \\text{ ~ } \\mathcal{N}(0, \\sigma^2, I)$\n",
    "\n",
    "\n",
    "* $P(\\beta) \\propto e^{\\frac{ -\\beta^{T}\\beta }{ 2\\sigma^{2} }}$\n",
    "\n",
    "\n",
    "* $\\ln{(P(\\beta)})$ is a *prior*, i.e. Gaussian with zero mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    " def gaussian_pdf(x, mu=0.0, sigma=1.0):\n",
    "    return (1 / (sigma * np.sqrt(2 * np.pi))) * np.exp(-(np.power(x - mu, 2) / (2 * np.power(sigma, 2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(x, mu=0, sigma=1):\n",
    "    return np.log(1 / (sigma * np.sqrt(2 * np.pi))) - (np.power(x - mu, 2) / (2 * np.power(sigma, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rpy2",
   "language": "python",
   "name": "rpy2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
